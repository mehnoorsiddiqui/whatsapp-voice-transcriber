/**
 * OpenAI APILib
 *
 * This file was automatically generated by APIMATIC v3.0 ( https://www.apimatic.io ).
 */

import { ApiResponse, FileWrapper, RequestOptions } from '../core';
import {
  CreateChatCompletionRequest,
  createChatCompletionRequestSchema,
} from '../models/createChatCompletionRequest';
import {
  CreateChatCompletionResponse,
  createChatCompletionResponseSchema,
} from '../models/createChatCompletionResponse';
import {
  CreateImageRequest,
  createImageRequestSchema,
} from '../models/createImageRequest';
import {
  CreateTranslationResponse,
  createTranslationResponseSchema,
} from '../models/createTranslationResponse';
import { ImagesResponse, imagesResponseSchema } from '../models/imagesResponse';
import { number, optional, string } from '../schema';
import { BaseController } from './baseController';

export class OpenAIController extends BaseController {
  /**
   * Transcribes audio into the input language.
   *
   * @param file            The audio file to transcribe, in one of these formats: mp3, mp4, mpeg, mpga,
   *                                       m4a, wav, or webm.
   * @param model           ID of the model to use. Only `whisper-1` is currently available.
   * @param prompt          An optional text to guide the model's style or continue a previous audio
   *                                       segment. The [prompt](/docs/guides/speech-to-text/prompting) should match
   *                                       the audio language.
   * @param responseFormat  The format of the transcript output, in one of these options: json, text,
   *                                       srt, verbose_json, or vtt.
   * @param temperature     The sampling temperature, between 0 and 1. Higher values like 0.8 will make
   *                                       the output more random, while lower values like 0.2 will make it more
   *                                       focused and deterministic. If set to 0, the model will use [log
   *                                       probability](https://en.wikipedia.org/wiki/Log_probability) to automatically
   *                                       increase the temperature until certain thresholds are hit.
   * @param language        The language of the input audio. Supplying the input language in [ISO-639-
   *                                       1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will
   *                                       improve accuracy and latency.
   * @return Response from the API call
   */
  async createTranscription(
    file: FileWrapper,
    model: string,
    prompt?: string,
    responseFormat?: string,
    temperature?: number,
    language?: string,
    requestOptions?: RequestOptions
  ): Promise<ApiResponse<CreateTranslationResponse>> {
    const req = this.createRequest('POST', '/audio/transcriptions');
    const mapped = req.prepareArgs({
      model: [model, string()],
      prompt: [prompt, optional(string())],
      responseFormat: [responseFormat, optional(string())],
      temperature: [temperature, optional(number())],
      language: [language, optional(string())],
    });
    req.formData({
      file: file,
      model: mapped.model,
      prompt: mapped.prompt,
      response_format: mapped.responseFormat,
      temperature: mapped.temperature,
      language: mapped.language,
    });
    return req.callAsJson(createTranslationResponseSchema, requestOptions);
  }

  /**
   * Creates an image given a prompt.
   *
   * @param body
   * @return Response from the API call
   */
  async createImage(
    body: CreateImageRequest,
    requestOptions?: RequestOptions
  ): Promise<ApiResponse<ImagesResponse>> {
    const req = this.createRequest('POST', '/images/generations');
    const mapped = req.prepareArgs({ body: [body, createImageRequestSchema] });
    req.header('Content-Type', 'application/json');
    req.json(mapped.body);
    return req.callAsJson(imagesResponseSchema, requestOptions);
  }

  /**
   * Creates a completion for the chat message
   *
   * @param body
   * @return Response from the API call
   */
  async createChatCompletion(
    body: CreateChatCompletionRequest,
    requestOptions?: RequestOptions
  ): Promise<ApiResponse<CreateChatCompletionResponse>> {
    const req = this.createRequest('POST', '/chat/completions');
    const mapped = req.prepareArgs({
      body: [body, createChatCompletionRequestSchema],
    });
    req.header('Content-Type', 'application/json');
    req.json(mapped.body);
    return req.callAsJson(createChatCompletionResponseSchema, requestOptions);
  }

  /**
   * Translates audio into English.
   *
   * @param file            The audio file to translate, in one of these formats: mp3, mp4, mpeg, mpga,
   *                                       m4a, wav, or webm.
   * @param model           ID of the model to use. Only `whisper-1` is currently available.
   * @param prompt          An optional text to guide the model's style or continue a previous audio
   *                                       segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in
   *                                       English.
   * @param responseFormat  The format of the transcript output, in one of these options: json, text,
   *                                       srt, verbose_json, or vtt.
   * @param temperature     The sampling temperature, between 0 and 1. Higher values like 0.8 will make
   *                                       the output more random, while lower values like 0.2 will make it more
   *                                       focused and deterministic. If set to 0, the model will use [log
   *                                       probability](https://en.wikipedia.org/wiki/Log_probability) to automatically
   *                                       increase the temperature until certain thresholds are hit.
   * @return Response from the API call
   */
  async createTranslation(
    file: FileWrapper,
    model: string,
    prompt?: string,
    responseFormat?: string,
    temperature?: number,
    requestOptions?: RequestOptions
  ): Promise<ApiResponse<CreateTranslationResponse>> {
    const req = this.createRequest('POST', '/audio/translations');
    const mapped = req.prepareArgs({
      model: [model, string()],
      prompt: [prompt, optional(string())],
      responseFormat: [responseFormat, optional(string())],
      temperature: [temperature, optional(number())],
    });
    req.formData({
      file: file,
      model: mapped.model,
      prompt: mapped.prompt,
      response_format: mapped.responseFormat,
      temperature: mapped.temperature,
    });
    return req.callAsJson(createTranslationResponseSchema, requestOptions);
  }
}
